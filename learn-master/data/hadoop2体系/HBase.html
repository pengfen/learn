HBase 简介

HBase Hadoop Database 是一个高可靠性 高性能 面向列 可伸缩 实时读写的分布式数据库
利用 Hadoop HDFS 作为其文件存储系统 利用 Hadoop MapReduce 来处理 HBase 中的海量数据 利用 Zookeeper 作为其分布式协同服务
主要用来存储非结构化和半结构化的松散数据 (列存 NoSQL 数据库)

HBase 数据模型
Row Key 一列一个 Row Key
Time Stamp 版本
CF1 列族 (可有一列也可有多列)

Column Family 列族 & qualifier 列

HBase 表中的每个列都归属于某个列族 列族必须作为表模式 (schema) 定义的一部分预先给出 如 create "test" "course"
列名以列族作为前缀 每个 "列族" 都可以有多个列成员 (column) 如 course:math, course:english 新的列族成员 (列) 可以随后按需, 动态加入
权限控制 存储以及调优都是在列族层面进行的
HBase 把同一列族里面的数据存储在同一目录下 由几个文件保存

Timestamp 时间戳

在 HBase 每个 cell 存储单元对同一份数据有多个版本 根据唯一的时间戳来区分每个版本之间的差异 不同版本的数据按照时间倒序排序 最新的数据版本排在最前面
时间戳的类型是 64 位整型
时间戳可以由 HBase (在数据写入时自动) 赋值 此时时间戳是精确到毫秒的当前系统时间
时间戳也可以由客户显式赋值 如果应用程序要避免数据版本冲突 就必须自己生成具有唯一性的时间戳

Cell 单元格 (由 {row key, column(=<Family> + <qualifier>), version}) 唯一确定的单元 cell 中数据是没有类型的 全部是字节码形式存贮

由行和列的坐标交叉决定
单元格是有版本的
单元格的内容是未解析的字节数组

HLog(WAL log)
HLog 文件就是一个普通的 Hadoop Sequence File, Sequence File 的 Key 是 HLogKey 对象 HLogKey 中记录了写入数据的归属信息 除了 table 和 region 名字外  同时还包括 sequence number 和 timestamp timestamp 是 "写入时间" sequence number 的起始值为 0 或者是最近一次存入文件系统中 sequence number
HLog SequenceFile 的 Value 是 HBase 的 KeyValue 对象 即对应 HFile 中的 KeyValue


HBase 体系架构

Master
为 Region server 分配 region
负责 Region server 的负载均衡
发现失效的 Region server 并重新分配其上的 region
管理用户对 table 的增删改操作

RegionServer
Region server 维护 region 处理对这些 region 的 IO 请求
Region server 负责切分在运行过程中变得过大的 region

Region
HBase 自动把表水平划分成多个区域 (region) 每个 region 会保存一个表里面某段连续的数据 每个表一开始只有一个 region 随着数据不断插入表 region 不断增大 当增大到一个阀值的时候 region 就会等分会两个新的 region (裂变)

当 table 中的行不断增多 就会有越来越多的 region 这样一张完整的表被保存在多个 Regionserver 上

Memstore 与 storefile
一个region 由多个 store 组成 一个 store 对应一个 CF (列族)
store 包括位于内存中的 memstore 和位于磁盘的 storefile 写操作先写入 memstore 当 memstore 中的数据达到某个阈值 hregionserver 会启动 flashcache 进程写入 storefile 每次写入形成单独的一个 storefile

当 storefile 文件的数量增长到一定阈值后 系统会进行合并 (minor, major compaction) 在合并过程中会进行版本合并和删除工作 (majar) 形成更大的 storefile

当一个 region 所有 storefile 的大小和超过一定阈值后 会把当前的 region 分割为两个 并由 hmaster 分配到相应的 regionserver 服务器 实现负载均衡

客户端检索数据 先在 memstore 找 找不到再找 storefile


HRegion 是 HBase 中分布式存储和负载均衡的最小单元 最小单元就表示不同的 HRegion 可以分布在不同的 HRegion server 上

HRegion 由一个或者多个 Store 组成 每个 store 保存一个 columns family

每个 Strore 又由一个 memStore 和 0 至多个 StoreFile 组成 (StoreFile 以 HFile 格式保存在 HDFS 上)

http://hbase.apache.org 下载 

hbase 单机安装
mkdir hbase
cd hbase
tar -txvf hbase...
ln -sf /root/hbase/hbase... /home/hbase
cd /home/hbase/conf
vi hbase-env.sh
export JAVA_HOME=/usr/local/java/jdk1.8.0_73
vi hbase-site.xml
<name>hbase.rootdir</name>
<value>file:///opt/hbase</value>
cd /home/hbase
./bin/start-hbase.sh
netstat -anlpt | grep java

http://peng4:60010

./bin/hbase shell #进入 hbase 数据库

create 't_student', 'cf1'
list
desc 't_student'
put 't_student', '007', 'cf1:name','lisi'
scan 't_student'

分布式环境
      HM (HMaster) RS (RegionServer)
peng1              Y
peng2              Y
peng3 Y            Y
peng4 Y            Y  

vi hbase-site.xml

<name>hbase.rootdir</name>
<value>hdfs://peng1:9000/hbase</value>

<name>hbase.cluster.distributed</name>
<value>true</value>

vi regionserver
peng1
peng2
peng3
peng4

配置 zk
vi hbase-env.sh
export HBASE_MANAGES_ZK=false #默认为true true 时使用内置的 zk
vi hbase-site.xml
<name>hbase.zookeeper.quorum</name>
<value>peng1,peng2,peng3</value>

<name>hbase.zookeeper.property.dataDir</name>
<value>/opt/zookeeper</value>

cp -a /home/hadoop/etc/hadoop/hdfs-site.xml /home/hbase/conf

复制 hbase 环境

./bin/start-hbase.sh
其它服务器开启 hmaster 使用 ./bin/hbase-daemon.sh start master
kill -9 pid # 挂一台服务器 (会自动切换为另一台)

create 't_person','cf1'
list
put 't_person','001','cf1:name','zs'
flush 't_person' # 每 flush 一次会生成一个文件
major_compact 't_person' #将多个文件合并为一个文件
./bin/hbase hfile -p -f /文件路径 # 打印数据信息